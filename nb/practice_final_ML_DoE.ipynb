{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_final_ML-DoE",
      "provenance": [],
      "authorship_tag": "ABX9TyMT4Y8f6fugCUKKcidYv3fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmontman/pub-choicemodels/blob/main/nb/practice_final_ML_DoE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU2pXeehVNOb"
      },
      "source": [
        "# Review Machine Learning and Design of Experiments\n",
        "\n",
        "We will cover:\n",
        "\n",
        "* Machine Learning (ML) models\n",
        "* Model validation\n",
        "* Design of Experiments (DoE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjkociFUR45n"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#  Machine Learning question) Fitting a ML model\n",
        "Including: \n",
        "* Sanity checking, for example, be careful when including variables such as availabilities, panel information or variables that might not be known when predicting new individuals.\n",
        "* A bit of Model tuning:\n",
        " * Which variables to include in the model? \n",
        " * Some fine tuning of the hyperparameters.\n",
        " * Using a train/test split for the tuning.\n",
        "\n",
        "\n",
        "# Machine Learning + Logit Models question)  Final model selection\n",
        " * Be able to justify a decision to go for one particular model (including the multinomial logit variants). This involves subjectively considering the accuracy, interpretability, among all models and decide.\n",
        "\n",
        "\n",
        "# Design of Experiments questions) (a few short questions)\n",
        "\n",
        " Some questions about understanding important isses in DoE.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1YluspjQui6"
      },
      "source": [
        "# 1) Fit a ML model to the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv9MvB2aRjtl"
      },
      "source": [
        "We have seen either **decision trees** or **multilayer perceptron neural networks**. We will have to fit one model, fine tune just a it a bit: \n",
        " * Try several values for the 'hyperparameter':\n",
        "   * The maximum depth of the tree in decision trees. `max_depth` argument in `DecisionTreeClassifier`.\n",
        "   * The size of the hidden layer in the neural network. This mean that we only need to try a 1-hidden layer network (`hidden_layer_sizes` argument in the sklearn package function `MLPClassifier`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-deKWYDwRRNd"
      },
      "source": [
        "### Some coments about Sanity checking\n",
        "\n",
        "*Note: This section ended up being a bit too verbose, what it means is: be careful and do not add 'invalid' variables to the models, pay attention to the description of the dataset.*\n",
        "\n",
        "Part of the benefit of ML models is that they can deal with complex variables or 'find transformations' of meaningful variable in an automatic way. Therefore we usually start by 'throwing all available variables at them' and check the results.\n",
        "\n",
        " This is quite the opposite of how we do things with the logit type models: we often carefully think about the relationship between the variables and the utility and define a model. \n",
        " \n",
        " The two methodologies, logit and ML models complement well, but we need to be careful when using all variables, since some of them might lead to models that are not useful in practice.\n",
        "\n",
        " * **Auxiliary variables such as panel id or availability information** they are a by product of the data-gathering process, they are used in the modeling but not as explanatory.\n",
        " * **Variables that would not be useful when predicting**\n",
        "   * Classic example is the choice variable itself. \n",
        "  * More subjective example can be variables that are not useful when predicting, because they are n. For example a dataset might be gathering information several choice problems, such as travel model (car, train, bus) and living area (city, suburb, rural area). In that case we should not use information about preferences of one subproblem for the other, because that data would not be available for new individuals (those that did not participate in the survey).\n",
        "   * Another subjective example: \n",
        "In the infidelity dataset, we have variables such as rating, the self-rating of their marriage. I would say that adding this variable can be 'too informative' and finding a model that explains affairs behavior but depends on the self-rating as explanatory variable is not very useful in practice. On the other hand, it can argued that knowing the effect of taht the selft-rating has in the behavior can be an important finding (imagine that we find that self-rating of the marriage does not influence the likelihood of infidelity).\n",
        " * **Variables that are not well documented or understood** This one is a bit artificial but if we have a dataset with variables that we do not really understand its meaning or how they are encoded in the dataset, using them can lead to results that are not very meaningful. \n",
        " \n",
        "  For example, variables such as availabilities or panel id are not useful explanatory variables, they are a by product of the data-gathering process, they are used in the modeling but not as explanatory.\n",
        "  \n",
        "**NOTE:** These problems are not specific to ML models, they can appear on more simple logit ones, but the flexibility of ML models makes them more susceptible. For example, adding the choice variable in a simple linear model might to be catastrophic beause the relationship between how it is encoded in the dataset and the utility is not a simple 'line'. But a ML model might be able  to pick a very complex pattern that is totally useless in practice.\n",
        "\n",
        "----\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G742QVZbQ9nf"
      },
      "source": [
        "# 2) Model selection, which model to choose among several"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xa3OcFo-QpD"
      },
      "source": [
        "**IMPORTANT!:** You are not required to have found a 'perfect model', just that you tried several reasonable alternatives, and demonstrate that you can compare them in a principled way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erwXChVyAmNi"
      },
      "source": [
        "In this exercise we have to compare all types of models and variations of the variables and make an justified decision for one model.\n",
        "\n",
        "A holdout dataset will be given to test the models (in addition to whatever statsitical tests you might use). This is another dataset, different from the test/train split that you might use to tune the machine learning model.\n",
        "\n",
        "\n",
        "A list of things to consider, it is non exhaustive\n",
        " * Explainability:\n",
        "    * Do we get an intutitive understanding of the model (usually linear vs machine learning)?\n",
        "    * Can we compute easy measures such as WTP? \n",
        "    * Within the logit family:\n",
        "      * Ordered logit is much more simple, might be worth sacrificing some predictive capacity. Even when we get statistically significance test that other models are better.\n",
        "      * Nested: How good is the nested structure? Does it make sense? Can we draw some insight about the process from it? \n",
        " * Accuracy in the holdout dataset: Which models are more accurate, and by how much.\n",
        " * Confusion matrix\n",
        "    * How are the errors distributed for each model? Does it make a difference when deciding for one of the candidate models?\n",
        "    * Maybe a model is accurate but produces  'degenerate' predictions, such all predictions go to the same class.\n",
        "    * Maybe some confusions are more serious than others, even to the point of preferring some model with slightly worse accuracy that makes less serious errors. Examples of errors: *predicting a cheap phone from the functional brand of smartphones when the actual preference is for an expensive smarthpone from the stylish brand* is a more serious error than *predicting a slighly cheaper phone within the same brand (the actual preference is a slighly more expensive phone whithin the same brand)*. In ordinal logit, the the farthest away the alternatives the worse the error is (predicting *totally disagree when the actual preference is totally agree* is worse than predicting *totally disagree when the actual preference is 'neutral'*). When there is a clear nesting structure, the errors within nests might be less serious than errors across nests (red bus when the true value is blue bus vs red bus when the true value is car), though it might be quite subjective.\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt90Kw-cQ7H2"
      },
      "source": [
        "#Design of Experiments\n",
        "\n",
        "These will be more of 'theory' or check you understanding questions, no need to program (but of course you might code if you want to double check something).\n",
        "The following is a list of potential questions that help you get and idea of the the actual questions that *might* appear in the exam.\n",
        "\n",
        "*I know they are not too specific, I hope you understand, we have to make an exam...*\n",
        "*They will be  clear and about important issues in DoE, nothing too far-fetched or academic.*\n",
        "\n",
        "* ## Given a design description, How many observations are needed to estimate all parameters?\n",
        "\n",
        "* ## Identify a potential problem in a given design\n",
        "\n",
        "* ## What is a pilot study? Why is a pilot study important? \n",
        "\n",
        "* ## How many attributes could be tested given a specify sample size and description?\n",
        "\n",
        "* ## Given a description, is it revealed preferences or stated preferences? Differences between the two?\n",
        "\n",
        "* ## Given a description, How would you encode variables (linear or dummy) ?\n",
        "\n",
        "* ## Given a design, Which observations/attributes would you remove to make it in a given the budget of observation?\n",
        "  * Will be obvious (no need of computing)\n",
        "\n",
        "* ## Which principles are clearly violated in this design?\n",
        " * From orthogonality,  minimal overlap, an level and utility balances...\n",
        "  * Will be obvious (no need of computing)\n",
        "\n",
        "* ## How many alternatives would be generated given a description? What kind of problems does it produce? How is it addressed when modelling?\n",
        "\n",
        "* ## Key differences between designs for linear regression and choice modelling? \n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMIqcjxK-teH"
      },
      "source": [
        "# Examples\n",
        "\n",
        "We will show several examples of 'fine tuning' of the ML models + sanity checking + comparisons.\n",
        "\n",
        "We will reuse the affairs dataset, a reminder of the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyzPlsofdvaG"
      },
      "source": [
        "# Description of the dataset\n",
        "\n",
        "A scientific paper making use of the dataset to develop a 'Theory of Extramarial Affairs' can be found [here](https://www.uibk.ac.at/econometrics/data/fair78.pdf).\n",
        "\n",
        "The dataset has 601 observations of the following variables:\n",
        "\n",
        "* **affairs:** The answer to the survey, the answers are encoded with numbers.\n",
        "  0 = None, 1 = Once, 2 = Twice, 3=Three times, 7= 4 to 10 times, 12= monthly, 12 = weekly, 12 = daily.\n",
        "  As we see, the information was encoded in such a way that we lose information about the more frequent answers, and the encoded numbers do not completely coincide with the frequencies. However, there is an ordinal relationship among the possible answer, from less frequent to more frequent.\n",
        "\n",
        "*  **gender:** Categorical variable indicating either male or female among the participants.\n",
        "\n",
        "* **age:** Numeric variable coding age in years: 17.5 = under 20, 22 = 20–24, 27 = 25–29, 32 = 30–34, 37 = 35–39, 42 = 40–44, 47 = 45–49, 52 = 50–54, 57 = 55 or over. \n",
        "\n",
        "* **yearsmarried:** Numeric variable coding number of years married: 0.125 = 3 months or less, 0.417 = 4–6 months, 0.75 = 6 months–1 year, 1.5 = 1–2 years, 4 = 3–5 years, 7 = 6–8 years, 10 = 9–11 years, 15 = 12 or more years.\n",
        "\n",
        "* **children:** Categorical variable indicating if there are children in the marriage.\n",
        "\n",
        "* **religiousness:** Categorical variable indicating how religious in the person, encoded as numbers: 1 = anti, 2 = not at all, 3 = slightly, 4 = somewhat, 5 = very.\n",
        "\n",
        "* **education:**: Categorical variable indicating the level of education. Encoded as numbers: 9 = grade school, 12 = high school graduate, 14 = some college, 16 = college graduate, 17 = some graduate work, 18 = master's degree, 20 = Ph.D., M.D., or other advanced degree.\n",
        "\n",
        "* **occupation:** Categorical variable classifying the profession of the individual. Encoded as numbers, and the meaning of the numbers has been somewhat lost in time. But it could be something like the one in this [link.](https://dictionary.fitbir.nih.gov/portal/publicData/dataElementAction!view.action?dataElementName=HollingsheadJobClassCat&publicArea=true)\n",
        "\n",
        "* **rating:** Categorical variable indicating how happy they are with the marriage. Encoded as numbers: 1 = very unhappy, 2 = somewhat unhappy, 3 = average, 4 = happier than average, 5 = very happy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb9SIunnASNB"
      },
      "source": [
        "\n",
        "\n",
        "# Preparing the environment\n",
        "*The preparation and dataset loading code is given to the students*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5zHGhgErHPd",
        "outputId": "7c435d65-aa24-4875-9775-b81818a09bf0"
      },
      "source": [
        "!pip install biogeme"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biogeme\n",
            "  Downloading biogeme-3.2.8.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biogeme) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from biogeme) (0.29.24)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from biogeme) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from biogeme) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from biogeme) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->biogeme) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->biogeme) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->biogeme) (1.15.0)\n",
            "Building wheels for collected packages: biogeme\n",
            "  Building wheel for biogeme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for biogeme: filename=biogeme-3.2.8-cp37-cp37m-linux_x86_64.whl size=4030751 sha256=51c9db805216067fc5d0dd4cec2fb2dd6bb45e22181cb259e65226344ede1db6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/52/61/de6c73d2bc17603c60e754e260bccb7d4da2503e97015ebd49\n",
            "Successfully built biogeme\n",
            "Installing collected packages: unidecode, biogeme\n",
            "Successfully installed biogeme-3.2.8 unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z0X9xZ8rChf"
      },
      "source": [
        "Load the packages, feel free to change the names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVB-TMkrFnb"
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import biogeme.database as db\n",
        "import biogeme.biogeme as bio\n",
        "import biogeme.models as models\n",
        "import biogeme.expressions as exp\n",
        "import biogeme.tools as tools"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEJvXwpekbvd"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Auxiliary functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKyKA_dj-IVp"
      },
      "source": [
        "The first function takes the dictionary of utilities, a pandas dataframe, and the name of the variable that contains the variable with the results of the choice. It returns the biogeme object with the model and the estimated 'results' object (the one we get the values, likelihoods, etc.)\n",
        "We have added the dictionary with the utilities to the biogeme object, in case we use it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OQ1ls2Bi_ot"
      },
      "source": [
        "def qbus_estimate_bgm(V, pd_df, tgtvar_name, modelname='bgmdef'):\n",
        " av_auto = V.copy()\n",
        " for key, value in av_auto.items():\n",
        "   av_auto[key] = 1\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        " logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprob )\n",
        " bgm_model.utility_dic = V.copy()\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM2f5-0w-_4b"
      },
      "source": [
        "The next function will calculate the predictions for a given biogeme object that was estimated with `qbus_estimate_bgm`. The output is the array with the choice probabilities. From the choice probabilities, this can be used to calculate accuracies, confusion matrices and the output of what-if scenarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Iau_IHHCzc"
      },
      "source": [
        "def qbus_simulate_bgm(qbus_bgm_model, betas, pred_pd_df):\n",
        "  av_auto = None\n",
        "  if hasattr(qbus_bgm_model, 'ord_probs'):\n",
        "    av_auto = qbus_bgm_model.ord_probs.copy()\n",
        "  else:\n",
        "    av_auto = qbus_bgm_model.utility_dic.copy()\n",
        "\n",
        "  for key, value in av_auto.items():\n",
        "    av_auto[key] = 1\n",
        "\n",
        "  targets = qbus_bgm_model.utility_dic.copy()\n",
        "  for key, value in targets.items():\n",
        "    if hasattr(qbus_bgm_model, 'nest_tuple'):\n",
        "      targets[key] = models.nested(qbus_bgm_model.utility_dic, av_auto, qbus_bgm_model.nest_tuple, key)\n",
        "    else:\n",
        "      if hasattr(qbus_bgm_model, 'ord_probs'):\n",
        "       targets[key] = qbus_bgm_model.ord_probs\n",
        "      else:\n",
        "       targets[key] = models.logit(qbus_bgm_model.utility_dic, av_auto, key)\n",
        "\n",
        "  bgm_db = db.Database('simul', pred_pd_df)\n",
        "  globals().update(bgm_db.variables)\n",
        "  bgm_pred_model = bio.BIOGEME(bgm_db, targets)\n",
        "  simulatedValues = bgm_pred_model.simulate(betas)\n",
        "  return simulatedValues"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnBLUPi-DjU7"
      },
      "source": [
        "The function `qbus_calc_accu_confusion` calculates the accuracies given the choice probability predictions a pandas dataset and the specification of the name that contains the actual choices in the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9l5cDGkzsfJ"
      },
      "source": [
        "def qbus_calc_accu_confusion(sim_probs, pd_df, choice_var):\n",
        "  which_max = sim_probs.idxmax(axis=1)\n",
        "  data = {'y_Actual':   pd_df[choice_var],\n",
        "          'y_Predicted': which_max\n",
        "        }\n",
        "\n",
        "  df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "  confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "  accu = np.mean(which_max == pd_df[choice_var])\n",
        "  return accu, confusion_matrix "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfxQpYLDzgm"
      },
      "source": [
        "The next function calculates the likelihood ratio test having to write a bit less code that the default biogeme function. The arguments are the results objects of the two models to be compared. The first is the more complex and the second is the reference model (**the order is important!**). The third argument is the significance level for the test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNVxPmK3rF2"
      },
      "source": [
        "def qbus_likeli_ratio_test_bgm(results_complex, results_reference, signif_level):\n",
        "  return tools.likelihood_ratio_test( (results_complex.data.logLike, results_complex.data.nparam),\n",
        "                                     (results_reference.data.logLike, results_reference.data.nparam), signif_level)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b7TaMhCEZIZ"
      },
      "source": [
        "The next function just updates the globals so we can use it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfHXGoLS1yHX"
      },
      "source": [
        "def qbus_update_globals_bgm(pd_df):\n",
        "   globals().update(db.Database('tmp_bg_bgm_for_glob', pd_df).variables)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buGCdfDc47M4"
      },
      "source": [
        "The next function calculates the nested logit version. Similar to the multinomial logit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEo3d3kJo2BV"
      },
      "source": [
        "def qbus_estimate_nested_bgm(V, pd_df, nests,  tgtvar_name, modelname='bgmdef'):\n",
        " av_auto = V.copy()\n",
        " for key, value in av_auto.items():\n",
        "   av_auto[key] = 1\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        " logprobnest = models.lognested (V, av_auto , nests , bgm_db.variables[tgtvar_name] )\n",
        " #logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprobnest )\n",
        " bgm_model.utility_dic = V.copy()\n",
        " bgm_model.nest_tuple = nests\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvu4rY2z0lnG"
      },
      "source": [
        "The auxiliary function for the ordered logit. The use is slightly different from the basic multinomial logit!\n",
        "* The `V` argument is just the expression of a utility function, not the dictionary mapping alternative ids to the utility functions.\n",
        "* The argument `ord_alt_ids` is a list with the ids of the alternatives **in the order that we want to impose**.The parameter to know about.\n",
        "\n",
        "Then the rest of the arguments are used as usual `pd_df` the pandas dataframe, `tgt_varname` the name of the variable with the choices, and an optional `modelname`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cNy29oJjLtM"
      },
      "source": [
        "def qbus_estimate_ordered_bgm(V, ord_alt_ids, pd_df, tgtvar_name, modelname='ord_bgm'):\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        "\n",
        " taus_map = {ord_alt_ids[0]: exp.Beta('tau1', -1, None, None, 0) }\n",
        " i = 1\n",
        " for id in ord_alt_ids[1:-1]:\n",
        "  taus_map[id] = taus_map[ ord_alt_ids[i-1] ] + exp.Beta('delta_'+ str(i + 1), i, 0, None, 0)\n",
        "  i = i + 1\n",
        "\n",
        " alt_probs_map = {ord_alt_ids[0]: dist.logisticcdf( taus_map[ord_alt_ids[0] ] - V_ord) }\n",
        "\n",
        " i = 1\n",
        " for id in ord_alt_ids[1:-1]:\n",
        "  alt_probs_map[id] = dist.logisticcdf( taus_map[id] - V_ord) - dist.logisticcdf( taus_map[ ord_alt_ids[i-1] ] - V_ord)\n",
        "  i = i + 1\n",
        "\n",
        " alt_probs_map[ord_alt_ids[i] ] = 1 - dist.logisticcdf( taus_map[ord_alt_ids[i-1]] - V_ord)\n",
        "\n",
        " logprob = exp.log(exp.Elem(alt_probs_map, bgm_db.variables[tgtvar_name]))\n",
        "\n",
        " #logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprob )\n",
        " bgm_model.utility_dic = V\n",
        " bgm_model.ord_probs = alt_probs_map.copy()\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aomoxdcWPWx7"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKsOP6X3PY0n"
      },
      "source": [
        "pd_dset = pd.read_csv('https://github.com/pmontman/pub-choicemodels/raw/main/data/affairs.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbn-wV4fH2UK"
      },
      "source": [
        "Lets take a look at the dataset as a reminder of the variables involved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qMOoQLgBRQaq",
        "outputId": "3c08c975-3760-42e2-be44-fecaca107a5b"
      },
      "source": [
        "pd_dset"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>affairs</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>yearsmarried</th>\n",
              "      <th>children</th>\n",
              "      <th>religiousness</th>\n",
              "      <th>education</th>\n",
              "      <th>occupation</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>37.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>no</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "      <td>32.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>57.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>7</td>\n",
              "      <td>female</td>\n",
              "      <td>32.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>32.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>601 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     affairs  gender   age  ...  education occupation  rating\n",
              "0          0    male  37.0  ...         18          7       4\n",
              "1          0  female  27.0  ...         14          6       4\n",
              "2          0  female  32.0  ...         12          1       4\n",
              "3          0    male  57.0  ...         18          6       5\n",
              "4          0    male  22.0  ...         17          6       3\n",
              "..       ...     ...   ...  ...        ...        ...     ...\n",
              "596        1    male  22.0  ...         12          2       5\n",
              "597        7  female  32.0  ...         18          5       4\n",
              "598        2    male  32.0  ...         17          6       5\n",
              "599        2    male  22.0  ...         18          6       2\n",
              "600        1  female  32.0  ...         14          1       5\n",
              "\n",
              "[601 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5694uuxuH-JJ"
      },
      "source": [
        "Transform categorical to numerical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfQsXckH_Dna"
      },
      "source": [
        "pd_dset['gender'] = pd_dset['gender'].factorize()[0]\n",
        "pd_dset['children'] = pd_dset['children'].factorize()[0]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWQtTeYol-LT"
      },
      "source": [
        "# Examples start here!\n",
        "\n",
        "**IMPORTANT:** These are examples of potential models and comparisons, for illustration, they are not strict prescriptions on how to do model tuning and comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkB1hVIalVxe"
      },
      "source": [
        "\n",
        "The first step is to create a a train/test split. *In this case the dataset is not too big, the size of the test set is 151, so conclusions about small differences in percentages are not super reliable, we will ignore that part for the sake of the exercise and assume that the test set is large enough to get reliable comparisons.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLjtxftiQ0Sa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "dset_train, dset_test = train_test_split(pd_dset, test_size = 0.25, random_state = 3840)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJNWtpJFLRmd"
      },
      "source": [
        "To save space, we will create a helper function that fits the ML model, calculates the predictions and returns the accurac and confusion matrix in the test set. *You do not need to do that, this is to avoid copy pasting the estimation and prediction code*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ROi1IfM9850"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "ml_model = None"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx9TvxPkL9zj"
      },
      "source": [
        "This helper function gets a first argument, `model_type`: either `dec_tree` or `neur_net`.\n",
        "Other argument is `hyperparam_val`, which will be the `max_depth` of the tree if we are using a decision tree, or the `hidden_layer_sizes` if we are using a neural net.\n",
        "Then we get a list of variables to remove from the datasets, so they are not used as explanatory variables.\n",
        "We have two other aguments, the train set and the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9wRTJCmSCoU"
      },
      "source": [
        "def get_ml_model_performance(model_type, hyperparam_val, variable_remove, train_set, test_set):\n",
        "\n",
        " if (model_type == 'dec_tree'):\n",
        "  print('Fitting a Decision Tree with max_depth: ' + str(hyperparam_val))\n",
        "  ml_model = DecisionTreeClassifier(max_features= None, max_depth=hyperparam_val, random_state=3840 )\n",
        "\n",
        " else:\n",
        "  print('Fitting a Neural Network  with hidden_layer_sizes: ' + str(hyperparam_val))\n",
        "  ml_model = MLPClassifier(hidden_layer_sizes = (hyperparam_val),\n",
        "                        activation='logistic', solver='lbfgs', max_iter=3500, n_iter_no_change=1000,batch_size=32, tol=0.000000001, random_state=3840, verbose=True, max_fun=15000)\n",
        "  \n",
        " # Train the model on training data\n",
        " ml_model.fit(train_set.drop(variables_remove, axis=1), pd.get_dummies(train_set['affairs']));\n",
        "\n",
        " predictions = ml_model.predict(test_set.drop(variables_remove, axis=1))\n",
        " ml_model_sim = pd.DataFrame(predictions, columns=[0, 1, 2, 3, 7, 12])\n",
        "\n",
        " ml_model_sim.index = test_set.index\n",
        " \n",
        " #pd.crosstab(index=test_set['affairs'], columns='count') / test_set.shape[0]\n",
        " return qbus_calc_accu_confusion(ml_model_sim, test_set, 'affairs')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twWMqzxcL6tZ"
      },
      "source": [
        "The first example, we forget to remove the choice variable in the decision tree.\n",
        "We see that the model gets perfect predictions on the test set, this should be a good hint of problems in the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0zzADB8BtmR",
        "outputId": "f3185a2b-95b7-4c82-b219-92bddac9ea5f"
      },
      "source": [
        "variables_remove = []\n",
        "hyp_max_depth = 6\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, Predicted   0   1   2   3   7   12\n",
              " Actual                            \n",
              " 0          101   0   0   0   0   0\n",
              " 1            0  14   0   0   0   0\n",
              " 2            0   0   4   0   0   0\n",
              " 3            0   0   0   8   0   0\n",
              " 7            0   0   0   0  13   0\n",
              " 12           0   0   0   0   0  11)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tMlQgyNWX3"
      },
      "source": [
        "If we use a very simple decision tree (maximum depth of 2), we might not detect the error! So a good idea is to try a complex model just to check for these types of problems. The range of the max_depth in decision trees usually goes between 2 and 14, though more extreme values have worked in some datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEgJtDa3-sjF",
        "outputId": "801bde5b-fdf0-4e4b-ba86-219c46ba9c57"
      },
      "source": [
        "variables_remove = []\n",
        "hyp_max_depth = 2\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7417218543046358, Predicted   0   12\n",
              " Actual            \n",
              " 0          101   0\n",
              " 1           14   0\n",
              " 2            4   0\n",
              " 3            8   0\n",
              " 7           13   0\n",
              " 12           0  11)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Clm1NS9NxqU"
      },
      "source": [
        "We now remove the affairs variable from the explanatory variables, and we get a more sensible accuracy/confusion matrix. At max_depth 4 we see that predictions are all of class 0: 'no affairs'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7diIZYeUXjL",
        "outputId": "d12bf0d5-3de5-4ef3-eae0-7f8323d1fdc8"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_max_depth = 4\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6688741721854304, Predicted    0\n",
              " Actual        \n",
              " 0          101\n",
              " 1           14\n",
              " 2            4\n",
              " 3            8\n",
              " 7           13\n",
              " 12          11)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCEpv2CQRBjP"
      },
      "source": [
        "A more complex tree, max_depth 6, predicts other classes, but incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN--STN1RAoC",
        "outputId": "aa27e2db-76d9-41d7-9dcf-bc635320ebc5"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_max_depth = 6\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6622516556291391, Predicted    0  7\n",
              " Actual           \n",
              " 0          100  1\n",
              " 1           14  0\n",
              " 2            3  1\n",
              " 3            8  0\n",
              " 7           13  0\n",
              " 12          11  0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2HqxEulRmsN"
      },
      "source": [
        "If we increase the complexity of the trees, we get worse accuracy, but the predictions errors are not that serious! For example, 9 confusions between 0 affairs and 13 or more affairs, in the previous model we had 11."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPa3REO1RnTt",
        "outputId": "048fc0e6-39a6-466b-9791-af5bf5eb39da"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_max_depth = 9\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6423841059602649, Predicted  0   1   2   3   7   12\n",
              " Actual                           \n",
              " 0          93   2   1   1   3   1\n",
              " 1          13   1   0   0   0   0\n",
              " 2           3   0   0   0   1   0\n",
              " 3           7   0   0   0   0   1\n",
              " 7          10   0   0   0   1   2\n",
              " 12          8   0   0   0   1   2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEf6GMLLN9Ut"
      },
      "source": [
        "We play around with removing some variables, for example occupation was encoded in a 'weird' way, not well documented. We might as well check what happens if we remove it. We could not get a good model for a range of max_depth values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnTtJfb2-5do",
        "outputId": "d6308c06-a6f0-4bec-980f-ea46b75636c9"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation']\n",
        "hyp_max_depth = 4\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6688741721854304, Predicted    0\n",
              " Actual        \n",
              " 0          101\n",
              " 1           14\n",
              " 2            4\n",
              " 3            8\n",
              " 7           13\n",
              " 12          11)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMKziMaQSqr"
      },
      "source": [
        "The 'rating' variable (self rating how happy they are with the marriage) reduces the applicability of the model (we need to know its value to make predictions, se we need to ask the individuals, we might as well ask them about the infidelity), we can try removing it.\n",
        "\n",
        "Playin around a bit with the depth of the tree, we see that we get relatively similar performance when comparing to the model that includes both rating and occupation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH2uMfWHPzLR",
        "outputId": "e9ad0d64-c05f-4616-8884-5826d3099ce0"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation', 'rating']\n",
        "hyp_max_depth = 9\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6490066225165563, Predicted  0   1   3   7   12\n",
              " Actual                       \n",
              " 0          95   1   1   3   1\n",
              " 1          12   1   0   0   1\n",
              " 2           4   0   0   0   0\n",
              " 3           7   0   1   0   0\n",
              " 7          12   0   0   0   1\n",
              " 12         10   0   0   0   1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H12yzD6FQUCw"
      },
      "source": [
        "We try also removing education, because the encoding to integer might be a bit 'fuzzy'. We get better accuracy here, and there are less extreme errors, a good candidate for the final model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8gIS5egQFuI",
        "outputId": "31e87c40-7ae7-4e27-dea2-dce42c43a182"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation', 'education', 'rating']\n",
        "hyp_max_depth = 5\n",
        "get_ml_model_performance('dec_tree', hyp_max_depth, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Decision Tree with max_depth: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6754966887417219, Predicted   0   1   12\n",
              " Actual                \n",
              " 0          100   1   0\n",
              " 1           14   0   0\n",
              " 2            4   0   0\n",
              " 3            8   0   0\n",
              " 7           13   0   0\n",
              " 12           9   0   2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXzzjk9UQCbM"
      },
      "source": [
        "With a **neural network** we can also get 'too good' results if we forget to remove some key variables. Also: please ignore the warnings about convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsHsEn_KUU45",
        "outputId": "5ab9edc7-274d-437b-93ac-b6937aac666e"
      },
      "source": [
        "variables_remove = []\n",
        "hyp_network_size = 32\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9933774834437086, Predicted   0   1   2   3   7   12\n",
              " Actual                            \n",
              " 0          101   0   0   0   0   0\n",
              " 1            0  14   0   0   0   0\n",
              " 2            0   0   4   0   0   0\n",
              " 3            0   0   0   8   0   0\n",
              " 7            0   0   0   0  12   1\n",
              " 12           0   0   0   0   0  11)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O55xs9mro9d"
      },
      "source": [
        "Removing the variable gets more reasonable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSugxoxDVzjN",
        "outputId": "f06eae72-abfc-402d-ef9e-56f706a897e1"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_network_size = 32\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6490066225165563, Predicted  0   1   3   7   12\n",
              " Actual                       \n",
              " 0          96   1   1   2   1\n",
              " 1          14   0   0   0   0\n",
              " 2           4   0   0   0   0\n",
              " 3           8   0   0   0   0\n",
              " 7          11   1   0   1   0\n",
              " 12         10   0   0   0   1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC-Fh8iQr4aa"
      },
      "source": [
        "Playing around with the hyperparameter of the size of the networks changes the predictions, in this case, a small network is better (though the accuracy is lower than a naive model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7MxI3duV3oL",
        "outputId": "3e171a03-f513-4730-e013-e366be581fb2"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_network_size = 6\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6622516556291391, Predicted  0   7   12\n",
              " Actual               \n",
              " 0          97   2   2\n",
              " 1          14   0   0\n",
              " 2           3   0   1\n",
              " 3           7   0   1\n",
              " 7          12   1   0\n",
              " 12          9   0   2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rkcfzu4sYbw"
      },
      "source": [
        "The range for the hyperparamter is more variable than in the decision trees, we can go from 1 (very rare, it degenerates in a linear model) or as many as observations (can produce perfec fits). We can try a few between 8 and 256 (be mindful it does not get too slow), from smaller to larger. In this case, a large neural netowrk does not produce better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKXVfZbysbYR",
        "outputId": "62ddd735-02a9-4729-fb64-b91b3c099143"
      },
      "source": [
        "variables_remove = ['affairs']\n",
        "hyp_network_size = 128\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6158940397350994, Predicted  0   1   2   3   7   12\n",
              " Actual                           \n",
              " 0          91   3   1   0   4   2\n",
              " 1          13   0   0   0   1   0\n",
              " 2           4   0   0   0   0   0\n",
              " 3           5   1   1   0   1   0\n",
              " 7          11   0   0   0   1   1\n",
              " 12          8   0   0   1   1   1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kKUvjMuti3b"
      },
      "source": [
        "We can check removin variables for the same reasons as in the decision trees.\n",
        "In this case the  results are close to the naive prediction, same accuracy but strictly better confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTp-m_ff7NmT",
        "outputId": "6054f9ea-6ffd-418d-d5f4-40d59c3cd0b1"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation']\n",
        "hyp_network_size = 10\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6688741721854304, Predicted   0   12\n",
              " Actual            \n",
              " 0          101   0\n",
              " 1           14   0\n",
              " 2            4   0\n",
              " 3            8   0\n",
              " 7           12   1\n",
              " 12          11   0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sAHwy77uc3B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OER5sE2I91fA",
        "outputId": "0f783cfa-e717-4d44-bf68-a94b811d8dba"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation']\n",
        "hyp_network_size = 32\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6556291390728477, Predicted  0   1   2   7   12\n",
              " Actual                       \n",
              " 0          97   0   3   1   0\n",
              " 1          12   1   0   1   0\n",
              " 2           4   0   0   0   0\n",
              " 3           7   0   0   1   0\n",
              " 7          10   1   1   0   1\n",
              " 12          8   1   1   0   1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMR9d1yb-vS6",
        "outputId": "40322c4e-c508-4a93-868e-d54444b0b14d"
      },
      "source": [
        "variables_remove = ['affairs', 'occupation']\n",
        "hyp_network_size = 128\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6556291390728477, Predicted  0   1   2   3   7   12\n",
              " Actual                           \n",
              " 0          93   2   0   3   2   1\n",
              " 1           9   2   0   0   2   1\n",
              " 2           3   0   1   0   0   0\n",
              " 3           5   0   0   1   2   0\n",
              " 7          13   0   0   0   0   0\n",
              " 12          7   0   1   0   1   2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeTNdQeOAdxO"
      },
      "source": [
        "Lets try removing rating only Directly superior as a 'naive' method that predicts the most popular class: it is the same accuracy, but the model predicts more classes (it is more useful) and the confusions are less extreme. This is subjective, in my opinion an error of *the model predicting 'no affairs' when the true is 7 affairs* is more serious than  *the model predicting 2 affairs when the true is 7 affairs*.\n",
        "So we here we get a reasonable model that uses less variables (compared to some of the previous models in this exercise)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VableGH_RLj",
        "outputId": "77bdf4f5-9be2-49ab-9818-40ea4c7474c8"
      },
      "source": [
        "variables_remove = ['affairs', 'rating']\n",
        "hyp_network_size = 18\n",
        "get_ml_model_performance('neur_net', hyp_network_size, variables_remove, dset_train, dset_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting a Neural Network  with hidden_layer_sizes: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6688741721854304, Predicted   0  1  2\n",
              " Actual             \n",
              " 0          99  1  1\n",
              " 1          13  1  0\n",
              " 2           3  0  1\n",
              " 3           8  0  0\n",
              " 7          11  1  1\n",
              " 12         11  0  0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}